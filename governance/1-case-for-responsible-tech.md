---
icon: sitemap
cover: ../.gitbook/assets/rtt-bg-case.png
coverY: 0
layout:
  cover:
    visible: true
    size: full
  title:
    visible: true
  description:
    visible: false
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
---

# (1) Case for Responsible Tech

## <img src="../.gitbook/assets/icon-w-alert.png" alt="https://www.notion.so/icons/forward_lightgray.svg" data-size="line">  **The Risk of Irresponsible Technology**

The trend of digitising government services and infrastructure offers potential benefits in efficiency and service delivery, but also introduces significant risks and challenges, particularly when the deployment of technology is not carefully managed or aligned with the needs and rights of diverse community users.

### **Problem/Risk Overview**

The core of the problem lies in the mismatch between the intentions of technology deployments and their real-world impacts, often exacerbated by misunderstanding the potential uses of the technology, or issues such as data gaps, privacy issues, and the deployment of poorly designed or inadequately tested technologies. These issues can lead to suboptimal urban services and planning, exacerbate social inequalities, and erode public trust in local governments.&#x20;

The risks associated with irresponsible technology deployment in urban development and municipal governance are multifaceted. They include the potential for exacerbating existing social inequalities, eroding public trust in government, and wasting public resources on technologies that do not meet community needs or respect community rights. Additionally, the deployment of technology without adequate consideration of privacy, security, and ethical implications can lead to unintended harm, particularly for vulnerable populations.

### **Specific Use-case Examples:**

*   **Smart Water Meters and Potential Community Mistrust**

    While local governments rolling out smart devices for measuring consumption views these meters as a way to efficiently collect consumption data (cost saving) and offer new services like early warning systems, some residents fear the remote control of water access, question the accuracy of the data and the security of data shared across third party telecommunications systems. This scenario underscores the importance of engaging with and addressing community concerns, and ensuring that systems offer direct value to the resident (such as through direct access to consumption data, and communications regarding potential on-site leaks).
*   **Data Collection in Informal Settlements**

    While governments hold dual mandates for servicing informal settlements, and protecting land, the collection of private data is done with consented uses. The collection of data on residents of informal settlements, ostensibly for the purpose of improving service delivery planning, presents a stark example of how data can be misused. When such data is also employed to plan evictions, it reveals an ethical breach. This dual use of data collection underscores the need for transparency, ethical guidelines, community consent and grievance/recourse mechanisms in data sharing and associated urban planning processes.
*   **Underutilised Open Data Portals**

    The significant investment in open data portals and dashboards, without a clear understanding of their usage or return on investment, highlights another facet of irresponsible technology deployment. While these platforms have the potential to enhance transparency and citizen engagement, their effectiveness is limited if they are not widely used or if the data they provide does not meet the needs of the community. This example points to the necessity of aligning technological investments with actual user needs - with implications deeper into the data production, sharing and collaboration culture of the organisation.

    *   **Case study: Sidewalk Labs in Toronto**

        [Sidewalk Labs](https://en.wikipedia.org/wiki/Sidewalk_Labs), a Google affiliate, proposed a high-tech urban development in Toronto that raised significant privacy and data governance concerns among citizens and privacy advocates. The extensive public backlash and feedback led to a more transparent dialogue about data collection, usage, and governance. The project ultimately was abandoned, but the discourse set a precedent for how community feedback can influence large-scale urban tech projects, emphasising the need for privacy protections and public participation in planning.

### More examples:

*   **Surveillance Technology in Smart Cities**

    Cities like San Diego, California, deployed smart streetlights intended to improve public safety and traffic planning by collecting video footage and other data. However, concerns arose regarding privacy and the potential for surveillance without adequate public oversight or consent. The backlash from the community and advocacy groups highlighted the need for clear policies on data use, privacy protections, and public consultation before implementing such technologies. In South Africa the use of CCTV in public spaces, by public and private role players, remains a relatively poorly regulated activity.

    *   **Case study**: **Oakland’s Privacy Advisory Commission**

        The city of Oakland, California, established a [Privacy Advisory Commission](https://www.oaklandca.gov/boards-commissions/privacy-advisory-board) to review city proposals involving surveillance technology. This commission, which includes community members, has the power to recommend privacy-protective policies and has led to the adoption of stricter guidelines for the use of surveillance tools by city agencies. This model demonstrates the effectiveness of involving community members directly in oversight roles.
*   **Predictive Policing Tools**

    Various cities have experimented with predictive policing technologies, which use data analytics to predict where crimes are likely to occur. In Cape Town, an example of this is the “shot spotter” program. While intended to make law enforcement more efficient and responsive, these tools have been criticised for their costs, and for reinforcing biases and leading to increased surveillance and policing of marginalised communities. Instances in cities like Los Angeles and Chicago have sparked debates about the ethical use of data in law enforcement and the need for transparency and accountability.
*   **Automated Decision Systems in Social Services**

    In some jurisdictions, automated decision-making systems have been used to allocate social services, such as housing assistance or child welfare interventions. Cases have emerged where these systems perpetuate biases or errors, leading to wrongful denials of services or benefits. For example, the Allegheny Family Screening Tool used in Pittsburgh to predict risk in child welfare cases raised concerns about fairness and the opacity of the decision-making process.

    *   **Case study: NYC Automated Decision Systems Task Force**

        New York City established a [task force](https://www.nyc.gov/site/adstaskforce/index.page) to review automated (algorithmic) decision systems used by city agencies, focusing on fairness, accountability, and transparency. The task force sought public input to understand concerns about how these systems might affect residents, particularly in areas like policing, social services, and housing. This initiative highlighted the importance of public oversight in the use of AI and algorithms by the government, leading to [recommendation](https://www.nyc.gov/assets/adstaskforce/downloads/pdf/ADS-Report-11192019.pdf)s for more transparent policies and practices.
    *   **Case study: Amsterdam and Helsinki Algorithm Registers**

        Both cities have [launched public algorithm registers](https://ai-regulation.com/amsterdam-and-helsinki-launch-algorithm-and-ai-register/) that allow citizens to see how algorithms are used in municipal services. These registers include information on the algorithm’s purpose, the data it uses, and the control mechanisms in place to ensure fairness and transparency. This initiative, driven by public demand for transparency, helps demystify government use of algorithms and fosters trust. <mark style="color:red;">(please find these links)</mark>

        Helsinki’s register&#x20;

        Amsterdam’s register
*   **Environmental Monitoring and Land Use**

    Technologies for environmental monitoring and land use planning, such as satellite imagery and AI algorithms, can sometimes lead to unintended consequences. For instance, in developing countries, such technologies have been used to identify illegal constructions or encroachments, leading to evictions without considering the socio-economic impacts on affected communities, leading to further marginalisation and at times subsequent land occupations in even less suitable locations. A key lesson is that these tools should not replace local engagement.
*   **Transportation and Mobility Apps**

    Ride-sharing and mobility apps have transformed urban transportation, but not without issues. In cities around the world, the rapid adoption of these platforms has led to traffic congestion, reduced use of public transportation, and conflicts with local taxi services. Additionally, the “gig economy” model used by these platforms has raised questions about labour rights and the economic sustainability of urban transportation systems.
